{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-train-ultralytics-yolo-on-carparts-segmentation-dataset.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the Carparts segmentation using Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carparts Segmentation using Ultralytics YOLO11\n",
        "\n",
        "This notebook serves as a starting point for training the YOLO11 model on [carparts](https://docs.ultralytics.com/datasets/segment/carparts-seg/) segmentation dataset."
      ],
      "metadata": {
        "id": "7EM2nwU4jshF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Structure\n",
        "\n",
        "The data distribution within the Carparts Segmentation Dataset is organized as outlined below:\n",
        "\n",
        "- **Training set**: Includes 3156 images, each accompanied by its corresponding annotations.\n",
        "- **Testing set**: Comprises 276 images, with each one paired with its respective annotations.\n",
        "- **Validation set**: Consists of 401 images, each having corresponding annotations."
      ],
      "metadata": {
        "id": "xypoYW_oYZAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applications\n",
        "\n",
        "Carparts Segmentation finds applications in automotive quality control, auto repair, e-commerce cataloging, traffic monitoring, autonomous vehicles, insurance processing, recycling, and smart city initiatives. It streamlines processes by accurately identifying and categorizing different vehicle components, contributing to efficiency and automation in various industries."
      ],
      "metadata": {
        "id": "R4SICbq5Yalg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "## Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset YAML File\n",
        "\n",
        "A YAML (Yet Another Markup Language) file defines the dataset configuration, including paths, classes, and other pertinent details. üòÄ"
      ],
      "metadata": {
        "id": "xE6ntKojSfSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```yaml\n",
        "# Ultralytics YOLO üöÄ, AGPL-3.0 license\n",
        "# Carparts-seg dataset by Ultralytics\n",
        "# Documentation: https://docs.ultralytics.com/datasets/segment/carparts-seg/\n",
        "# Example usage: yolo train data=carparts-seg.yaml\n",
        "# parent\n",
        "# ‚îú‚îÄ‚îÄ ultralytics\n",
        "# ‚îî‚îÄ‚îÄ datasets\n",
        "#     ‚îî‚îÄ‚îÄ carparts-seg  ‚Üê downloads here (132 MB)\n",
        "\n",
        "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "path: ../datasets/carparts-seg # dataset root dir\n",
        "train: train/images # train images (relative to 'path') 3516 images\n",
        "val: valid/images # val images (relative to 'path') 276 images\n",
        "test: test/images # test images (relative to 'path') 401 images\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: back_bumper\n",
        "  1: back_door\n",
        "  2: back_glass\n",
        "  3: back_left_door\n",
        "  4: back_left_light\n",
        "  5: back_light\n",
        "  6: back_right_door\n",
        "  7: back_right_light\n",
        "  8: front_bumper\n",
        "  9: front_door\n",
        "  10: front_glass\n",
        "  11: front_left_door\n",
        "  12: front_left_light\n",
        "  13: front_light\n",
        "  14: front_right_door\n",
        "  15: front_right_light\n",
        "  16: hood\n",
        "  17: left_mirror\n",
        "  18: object\n",
        "  19: right_mirror\n",
        "  20: tailgate\n",
        "  21: trunk\n",
        "  22: wheel\n",
        "\n",
        "# Download script/URL (optional)\n",
        "download: https://github.com/ultralytics/assets/releases/download/v0.0.0/carparts-seg.zip\n",
        "```"
      ],
      "metadata": {
        "id": "h8go3HNgN0WU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n",
        "Train YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ],
      "metadata": {
        "id": "fMV-sNfiSt_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-seg.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=\"carparts-seg.yaml\", epochs=10, imgsz=640, batch=32, workers=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgMYUvlNLvy",
        "outputId": "3f34e40b-3abb-4156-cca4-b0de0b9f7334"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.90M/5.90M [00:00<00:00, 115MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.58 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.pt, data=carparts-seg.yaml, epochs=10, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=64, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
            "Overriding model.yaml nc=80 with nc=23\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    687925  ultralytics.nn.modules.head.Segment          [23, 32, 64, [64, 128, 256]]  \n",
            "YOLO11n-seg summary: 355 layers, 2,847,093 parameters, 2,847,077 gradients, 10.4 GFLOPs\n",
            "\n",
            "Transferred 510/561 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/carparts-seg/train/labels.cache... 3156 images, 116 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3156/3156 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/carparts-seg/valid/labels.cache... 401 images, 12 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 401/401 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00037, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      6.16G      1.319      2.775      4.069      1.475        110        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:38<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.914     0.0768      0.131     0.0946      0.914     0.0761      0.132       0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      6.09G      1.066      1.904      2.492      1.232        106        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:12<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.517      0.361      0.318      0.229      0.517      0.362      0.319      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10       6.2G     0.9372      1.651      1.655      1.134         88        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:15<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.508      0.555       0.47      0.354      0.466        0.6      0.473      0.332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10       6.1G      0.873      1.529      1.386      1.091        102        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:10<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.582      0.542      0.551      0.429      0.592      0.525      0.554      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      6.18G     0.8182      1.407      1.205      1.057         99        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:10<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.562      0.652      0.613      0.469      0.544      0.653       0.61      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10       6.2G     0.7859      1.328      1.111      1.035        109        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:13<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042       0.54      0.683      0.611      0.484      0.542      0.689      0.619      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      6.11G     0.7399      1.248      1.015      1.009         82        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:10<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042       0.59      0.735      0.647      0.522      0.593      0.734      0.655      0.501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      6.09G     0.7107      1.193     0.9572     0.9904         94        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:10<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.595      0.755      0.646      0.534      0.597      0.757      0.656      0.509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      6.22G     0.6806      1.144     0.9086     0.9789        116        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:12<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.564      0.731      0.637      0.523      0.563      0.729      0.644      0.497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      6.15G     0.6523      1.103     0.8649     0.9568         87        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:10<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.601      0.789      0.676      0.561      0.604      0.787      0.686      0.536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.229 hours.\n",
            "Optimizer stripped from runs/segment/train/weights/last.pt, 6.0MB\n",
            "Optimizer stripped from runs/segment/train/weights/best.pt, 6.0MB\n",
            "\n",
            "Validating runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.3.58 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n-seg summary (fused): 265 layers, 2,839,053 parameters, 0 gradients, 10.2 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:13<00:00,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042        0.6      0.789      0.676       0.56      0.603      0.787      0.686      0.534\n",
            "           back_bumper         94         94      0.885      0.978      0.926      0.742      0.884      0.977      0.926      0.703\n",
            "             back_door        158        159      0.797      0.887        0.9      0.787      0.798      0.887      0.899      0.753\n",
            "            back_glass        114        115      0.884      0.913      0.934      0.801      0.886      0.913      0.934      0.767\n",
            "        back_left_door         15         15      0.518       0.86      0.615      0.535      0.516      0.853      0.615      0.481\n",
            "       back_left_light         19         19      0.538      0.737      0.611      0.476      0.552      0.737      0.611      0.431\n",
            "            back_light        161        226      0.815       0.81       0.83        0.6      0.825      0.819      0.839      0.581\n",
            "       back_right_door         12         12      0.369      0.833      0.607      0.532      0.369      0.833      0.607      0.504\n",
            "      back_right_light         13         13      0.427      0.745      0.565      0.455      0.419      0.722      0.565       0.46\n",
            "          front_bumper        208        208      0.913      0.981      0.954      0.872      0.913      0.981      0.954      0.857\n",
            "            front_door        167        167       0.83      0.922      0.924      0.817      0.831      0.922      0.924      0.795\n",
            "           front_glass        214        214      0.934      0.986       0.97      0.898      0.934      0.985       0.97      0.896\n",
            "       front_left_door         15         15      0.526          1      0.794      0.718       0.53          1      0.794      0.645\n",
            "      front_left_light         30         30      0.484        0.6      0.542       0.37       0.49        0.6      0.542       0.37\n",
            "           front_light        248        373      0.871      0.851      0.883      0.678      0.879      0.855      0.888      0.649\n",
            "      front_right_door         12         12      0.389      0.833      0.451      0.398      0.391      0.833      0.451      0.336\n",
            "     front_right_light         26         26      0.498      0.731      0.524      0.433      0.504      0.731      0.524      0.419\n",
            "                  hood        214        214      0.916      0.973      0.944      0.842      0.916      0.972      0.944      0.846\n",
            "           left_mirror         31         31      0.451      0.581      0.429      0.291      0.453      0.581      0.427      0.267\n",
            "                object          1          1          0          0          0          0          0          0          0          0\n",
            "          right_mirror         31         31      0.509      0.742       0.54      0.372      0.506      0.728       0.54      0.347\n",
            "              tailgate          5          5      0.467        0.8      0.513      0.405      0.471        0.8      0.558      0.428\n",
            "                 trunk          9          9      0.416      0.889      0.716      0.601      0.366      0.778      0.662      0.486\n",
            "                 wheel         34         53      0.368      0.494      0.387       0.26      0.441      0.585      0.603      0.271\n",
            "Speed: 0.3ms preprocess, 3.4ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Dataset sample image](https://github.com/ultralytics/docs/releases/download/0/dataset-sample-image.avif)"
      ],
      "metadata": {
        "id": "_Hapx6WkS--T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict\n",
        "\n",
        "YOLO11 may be used directly in the Command Line Interface (CLI) with a yolo command for a variety of tasks and modes and accepts additional arguments, i.e. imgsz=640. See a full list of available [yolo arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/)."
      ],
      "metadata": {
        "id": "mKAUvDAbTEjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(f\"{results.save_dir}/weights/best.pt\")  # load a fine-tuned model\n",
        "\n",
        "# Inference using the model (img/video/stream)\n",
        "results = model.predict(\"https://github.com/ultralytics/assets/releases/download/v0.0.0/carparts-image.jpg\", save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzTbeqK_TB6t",
        "outputId": "8855b131-ff07-4b68-ad67-fd215c694f20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://github.com/ultralytics/assets/releases/download/v0.0.0/carparts-image.jpg locally at carparts-image.jpg\n",
            "image 1/1 /content/carparts-image.jpg: 384x640 1 front_bumper, 1 front_glass, 1 front_left_door, 1 front_right_door, 1 front_right_light, 1 hood, 5 wheels, 80.5ms\n",
            "Speed: 2.2ms preprocess, 80.5ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://github.com/user-attachments/assets/436ded05-9203-4bb7-883b-f7a1f9a399c1\" width=\"600\">"
      ],
      "metadata": {
        "id": "lmNKY3rWWsvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export\n",
        "\n",
        "Export a YOLO11 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO11 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- üí° ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n",
        "- üí° ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n",
        "|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo11n.pt`              | ‚úÖ        | -                                                                    |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo11n.torchscript`     | ‚úÖ        | `imgsz`, `optimize`, `batch`                                         |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo11n.onnx`            | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo11n_openvino_model/` | ‚úÖ        | `imgsz`, `half`, `dynamic`, `int8`, `batch`                          |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo11n.engine`          | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo11n.mlpackage`       | ‚úÖ        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo11n_saved_model/`    | ‚úÖ        | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo11n.pb`              | ‚ùå        | `imgsz`, `batch`                                                     |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo11n.tflite`          | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo11n_edgetpu.tflite`  | ‚úÖ        | `imgsz`                                                              |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo11n_web_model/`      | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo11n_paddle_model/`   | ‚úÖ        | `imgsz`, `batch`                                                     |\n",
        "| [MNN](https://docs.ultralytics.com/integrations/mnn)                     | `mnn`             | `yolo11n.mnn`             | ‚úÖ        | `imgsz`, `batch`, `int8`, `half`                                     |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo11n_ncnn_model/`     | ‚úÖ        | `imgsz`, `half`, `batch`                                             |\n",
        "| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500)          | `imx`             | `yolov8n_imx_model/`      | ‚úÖ        | `imgsz`, `int8`                                                      |\n",
        "| [RKNN](https://docs.ultralytics.com/integrations/rockchip-rknn)          | `rknn`            | `yolo11n_rknn_model/`     | ‚úÖ        | `imgsz`, `batch`, `name`                                             |"
      ],
      "metadata": {
        "id": "vWBYYdXhTkN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(f\"{results.save_dir}/weights/best.pt\")  # load a fine-tuned model\n",
        "\n",
        "# Export the model\n",
        "model.export(format=\"onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "S4nWG40CTlOD",
        "outputId": "c727cbf1-7fad-4c32-9872-2501309e765f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.58 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n-seg summary (fused): 265 layers, 2,839,053 parameters, 0 gradients, 10.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/segment/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 59, 8400), (1, 32, 160, 160)) (5.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.47...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 2.7s, saved as '/content/runs/segment/train/weights/best.onnx' (11.1 MB)\n",
            "\n",
            "Export complete (4.6s)\n",
            "Results saved to \u001b[1m/content/runs/segment/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=segment model=/content/runs/segment/train/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=segment model=/content/runs/segment/train/weights/best.onnx imgsz=640 data=/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/carparts-seg.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/runs/segment/train/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}
