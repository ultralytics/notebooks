{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-count-the-objects-using-ultralytics-yolo.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  \n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the Ultralytics YOLO models validation results exports in different formats notebook üöÄ Ultralytics <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ],
      "metadata": {
        "id": "MwKH62l2dYD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ultralytics YOLO Model Validation and Results Export\n",
        "\n",
        "This notebook demonstrates how to validate a YOLO model and export the validation results in multiple formats including CSV, HTML, XML, SQL, and JSON. This is particularly useful for:\n",
        "\n",
        "- **Model Performance Analysis**: Get detailed metrics for each class i.e Precision, Recall, mAP.\n",
        "- **Data Integration**: Export results to different formats for integration in the exisiting pipeline of the project."
      ],
      "metadata": {
        "id": "main-title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ],
      "metadata": {
        "id": "o-WxHpU1Y1en"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEXdyKGvYBcN",
        "outputId": "8ae3f94a-4c9d-4e65-b540-78c5a200a1ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.156 üöÄ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.5/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics  # Install Ultralytics YOLO package\n",
        "\n",
        "# Import and verify installation\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Validation\n",
        "\n",
        "Here we load a pre-trained YOLO11 nano model and validate it on the COCO8 dataset. The validation process evaluates the model's performance across different object classes and generates comprehensive metrics including:\n",
        "\n",
        "- **Precision:** Measures how many predicted positives are actually correct, minimizing false positives.\n",
        "\n",
        "- **Recall:** Measures how well the model captures actual positives, minimizing false negatives.\n",
        "\n",
        "- **F1-Score:** Harmonic mean of precision and recall, balancing precision-recall trade-offs.\n",
        "\n",
        "- **mAP (mean Average Precision):** Mean precision across classes and IoU thresholds, summarizing detection performance.\n",
        "\n",
        "- **Confusion Matrix:** Tabular summary of prediction results, highlighting class-wise errors and accuracy.\n",
        "\n",
        "üí° **Tip**: Replace `\"coco8.yaml\"` with your custom dataset configuration file if using a custom-trained model."
      ],
      "metadata": {
        "id": "BS5DF2e4Y4R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Load pre-trained YOLO11 nano model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Validate the model on COCO8 dataset\n",
        "# For custom models, replace \"coco8.yaml\" with your data.yaml file\n",
        "metrics = model.val(data=\"coco8.yaml\", verbose=True)"
      ],
      "metadata": {
        "id": "-2Y5WSONYW1A",
        "outputId": "134abf9d-0225-4b8e-a7bc-d443ae3d445f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.156 üöÄ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 763.0¬±577.5 MB/s, size: 54.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17       0.57       0.85      0.847      0.632\n",
            "                person          3         10      0.557        0.6      0.585      0.272\n",
            "                   dog          1          1      0.548          1      0.995      0.697\n",
            "                 horse          1          2      0.531          1      0.995      0.674\n",
            "              elephant          1          2      0.371        0.5      0.516      0.256\n",
            "              umbrella          1          1      0.569          1      0.995      0.995\n",
            "          potted plant          1          1      0.847          1      0.995      0.895\n",
            "Speed: 25.4ms preprocess, 366.1ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation Results Export\n",
        "\n",
        "The Ultralytics YOLO metrics object provides several convenient methods to export validation results in different formats. This section demonstrates how to export the above validated data in various formats for different use cases."
      ],
      "metadata": {
        "id": "LT6kvd-hY7L_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pandas DataFrame\n",
        "\n",
        "The DataFrame format is perfect for immediate analysis within Python. It provides a structured view of per-class performance metrics that can be easily manipulated, filtered, and analyzed."
      ],
      "metadata": {
        "id": "jnrwINL1afQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results as pandas DataFrame\n",
        "val_df = metrics.to_df()\n",
        "print(val_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-UIqYqrY9O7",
        "outputId": "2ea53934-8162-4268-c222-e383d0df078b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     class_name    box-p  box-r   box-f1  box-map  box-map50  box-map75\n",
            "0        person  0.55725    0.6  0.57783  0.63162    0.84684     0.6918\n",
            "1           dog  0.54802    1.0  0.70803  0.63162    0.84684     0.6918\n",
            "2         horse  0.53058    1.0  0.69331  0.63162    0.84684     0.6918\n",
            "3      elephant  0.37078    0.5  0.42580  0.63162    0.84684     0.6918\n",
            "4      umbrella  0.56900    1.0  0.72531  0.63162    0.84684     0.6918\n",
            "5  potted plant  0.84718    1.0  0.91727  0.63162    0.84684     0.6918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSV\n",
        "\n",
        "CSV is widely used plain-text format for data export/import across Excel, Google Sheets, and other tabular tools."
      ],
      "metadata": {
        "id": "Y1ggdrpsa1Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results as CSV format\n",
        "val_csv = metrics.to_csv()\n",
        "print(val_csv)\n",
        "\n",
        "# Optionally save to file\n",
        "csv_filename = \"validation_results.csv\"\n",
        "with open(csv_filename, 'w') as f:\n",
        "    f.write(val_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq_eJc_5a6w_",
        "outputId": "5078b964-d2f4-45af-828a-35c840dbc633"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",class_name,box-p,box-r,box-f1,box-map,box-map50,box-map75\n",
            "0,person,0.55725,0.6,0.57783,0.63162,0.84684,0.6918\n",
            "1,dog,0.54802,1.0,0.70803,0.63162,0.84684,0.6918\n",
            "2,horse,0.53058,1.0,0.69331,0.63162,0.84684,0.6918\n",
            "3,elephant,0.37078,0.5,0.4258,0.63162,0.84684,0.6918\n",
            "4,umbrella,0.569,1.0,0.72531,0.63162,0.84684,0.6918\n",
            "5,potted plant,0.84718,1.0,0.91727,0.63162,0.84684,0.6918\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SQL\n",
        "\n",
        "Enables structured storage, querying, and integration with relational databases like MySQL or PostgreSQL.\n",
        "\n",
        "üí° **Tip**: To view the SQL file, open the [SQLite Viewer](https://inloop.github.io/sqlite-viewer/) and upload the `results.db` file."
      ],
      "metadata": {
        "id": "7HLVkPHPa_CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to SQL database\n",
        "metrics.to_sql()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOrl79b4bBXo",
        "outputId": "f6edfaaf-0d4d-495e-ca46-2dddd497e292"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to SQL table 'results' in 'results.db'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Export Formats\n",
        "\n",
        "Ultralytics YOLO also supports exporting validation results to HTML, XML, and JSON formats."
      ],
      "metadata": {
        "id": "additional-formats"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results in HTML format and optionally export\n",
        "val_html = metrics.to_html()\n",
        "print(val_html)\n",
        "with open('validation_results.html', 'w') as f:\n",
        "    f.write(val_html)\n",
        "\n",
        "# Export results in XML format\n",
        "val_xml = metrics.to_xml()\n",
        "with open('validation_results.xml', 'w') as f:\n",
        "    f.write(val_xml)\n",
        "\n",
        "# Export results in JSON format\n",
        "val_json = metrics.to_json()\n",
        "with open('validation_results.json', 'w') as f:\n",
        "    f.write(val_json)"
      ],
      "metadata": {
        "id": "additional-exports",
        "outputId": "e00a86a8-3694-4cb3-f7fb-3f49b52305b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<table border=\"1\" class=\"dataframe\">\n",
            "  <thead>\n",
            "    <tr style=\"text-align: right;\">\n",
            "      <th>class_name</th>\n",
            "      <th>box-p</th>\n",
            "      <th>box-r</th>\n",
            "      <th>box-f1</th>\n",
            "      <th>box-map</th>\n",
            "      <th>box-map50</th>\n",
            "      <th>box-map75</th>\n",
            "    </tr>\n",
            "  </thead>\n",
            "  <tbody>\n",
            "    <tr>\n",
            "      <td>person</td>\n",
            "      <td>0.55725</td>\n",
            "      <td>0.6</td>\n",
            "      <td>0.57783</td>\n",
            "      <td>0.63162</td>\n",
            "      <td>0.84684</td>\n",
            "      <td>0.6918</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>dog</td>\n",
            "      <td>0.54802</td>\n",
            "      <td>1.0</td>\n",
            "      <td>0.70803</td>\n",
            "      <td>0.63162</td>\n",
            "      <td>0.84684</td>\n",
            "      <td>0.6918</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>horse</td>\n",
            "      <td>0.53058</td>\n",
            "      <td>1.0</td>\n",
            "      <td>0.69331</td>\n",
            "      <td>0.63162</td>\n",
            "      <td>0.84684</td>\n",
            "      <td>0.6918</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>elephant</td>\n",
            "      <td>0.37078</td>\n",
            "      <td>0.5</td>\n",
            "      <td>0.42580</td>\n",
            "      <td>0.63162</td>\n",
            "      <td>0.84684</td>\n",
            "      <td>0.6918</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>umbrella</td>\n",
            "      <td>0.56900</td>\n",
            "      <td>1.0</td>\n",
            "      <td>0.72531</td>\n",
            "      <td>0.63162</td>\n",
            "      <td>0.84684</td>\n",
            "      <td>0.6918</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>potted plant</td>\n",
            "      <td>0.84718</td>\n",
            "      <td>1.0</td>\n",
            "      <td>0.91727</td>\n",
            "      <td>0.63162</td>\n",
            "      <td>0.84684</td>\n",
            "      <td>0.6918</td>\n",
            "    </tr>\n",
            "  </tbody>\n",
            "</table>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix Export\n",
        "\n",
        "The confusion matrix provides detailed insights into model performance by showing:\n",
        "\n",
        "- **True vs Predicted classifications:** Displays how many predictions matched the actual class for each label.\n",
        "\n",
        "- **Misclassification patterns:** Highlights confusion between similar or overlapping classes in the dataset.\n",
        "\n",
        "- **Background vs object detection:** Reveals how well the model distinguishes foreground objects from background noise.\n",
        "\n",
        "- **Class-specific strengths and weaknesses:** Identifies which classes are consistently well-predicted and which ones struggle.\n",
        "\n",
        "üí° **Tip**: The confusion matrix can also be exported to the same formats as the validation metrics."
      ],
      "metadata": {
        "id": "od_0gPE6ZHjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display in Pandas Dataframe\n",
        "cm_df = metrics.confusion_matrix.to_df()\n",
        "print(cm_df.head())  # Display first 5 rows of confusion matrix\n",
        "\n",
        "# Export in CSV format\n",
        "cm_csv = metrics.confusion_matrix.to_csv()\n",
        "with open('confusion_matrix.csv', 'w') as f:\n",
        "    f.write(cm_csv)\n",
        "\n",
        "# Export in SQL format\n",
        "metrics.confusion_matrix.to_sql()\n",
        "\n",
        "# Other formats\n",
        "# print(metrics.confusion_matrix.to_html())\n",
        "# print(metrics.confusion_matrix.to_json())\n",
        "# print(metrics.confusion_matrix.to_xml())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqy2jPI0ZGPH",
        "outputId": "2d0a1842-14b9-451c-be86-20906d73ee27"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Predicted  person  bicycle  car  motorcycle  airplane  bus  train  truck  \\\n",
            "0      person     4.0      0.0  0.0         0.0       0.0  0.0    0.0    0.0   \n",
            "1     bicycle     0.0      0.0  0.0         0.0       0.0  0.0    0.0    0.0   \n",
            "2         car     0.0      0.0  0.0         0.0       0.0  0.0    0.0    0.0   \n",
            "3  motorcycle     0.0      0.0  0.0         0.0       0.0  0.0    0.0    0.0   \n",
            "4    airplane     0.0      0.0  0.0         0.0       0.0  0.0    0.0    0.0   \n",
            "\n",
            "   boat  ...  sink  refrigerator  book  clock  vase  scissors  teddy_bear  \\\n",
            "0   0.0  ...   0.0           0.0   0.0    0.0   0.0       0.0         0.0   \n",
            "1   0.0  ...   0.0           0.0   0.0    0.0   0.0       0.0         0.0   \n",
            "2   0.0  ...   0.0           0.0   0.0    0.0   0.0       0.0         0.0   \n",
            "3   0.0  ...   0.0           0.0   0.0    0.0   0.0       0.0         0.0   \n",
            "4   0.0  ...   0.0           0.0   0.0    0.0   0.0       0.0         0.0   \n",
            "\n",
            "   hair_drier  toothbrush  background  \n",
            "0         0.0         0.0         2.0  \n",
            "1         0.0         0.0         0.0  \n",
            "2         0.0         0.0         0.0  \n",
            "3         0.0         0.0         0.0  \n",
            "4         0.0         0.0         0.0  \n",
            "\n",
            "[5 rows x 82 columns]\n",
            "Results saved to SQL table 'results' in 'results.db'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional Resources  \n",
        "\n",
        "‚úÖ Docs: https://docs.ultralytics.com/modes/val/\n",
        "\n",
        "‚úÖ GitHub: https://github.com/ultralytics/ultralytics/\n",
        "\n",
        "üåü Explore the [Ultralytics Notebooks](https://github.com/ultralytics/notebooks/) to boost your AI journey! üöÄ\n",
        "\n",
        "Built with üíô by [Ultralytics](https://ultralytics.com/)  "
      ],
      "metadata": {
        "id": "summary-section"
      }
    }
  ]
}